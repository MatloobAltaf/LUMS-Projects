# -*- coding: utf-8 -*-
"""ML_Project_SpeakerRecognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17JJ2khTFENPmz-zAiNYTYGzi7OpCOL4Y

# Create Dataset
"""

!unzip /content/drive/MyDrive/Colab Notebooks/ML-Project/LUMS_FALL2020_PROJECT_DATA.zip

!pip install python_speech_features

# import python_speech_features as mfcc
from scipy.io.wavfile import read
import numpy as np
import os
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt
from sklearn.metrics import precision_recall_fscore_support
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import confusion_matrix

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
tf.test.gpu_device_name()

# !unzip "/content/drive/MyDrive/LUMS_FALL2020_PROJECT_DATA.zip" -d "/content/drive/MyDrive/ml project"

"""Get features from audio files"""

def get_MFCC(audio, sr):
    features = mfcc.mfcc(audio, sr, 0.025, 0.01, 13, appendEnergy = True)
    return np.mean(features, axis=0)

# for Speaker Recognition 
your_path = "/content/drive/MyDrive/Ml assignmentsa/ml project"
test_path=your_path+"/Speaker_Recognition/Test"
train_path=your_path+"/Speaker_Recognition/Train"
validation_path=your_path+"/Speaker_Recognition/Valid"

"""Dataset creation function"""

def dataset_generator(path):
  speaker=os.listdir(path)
  output=np.array([]);
  for a,s in enumerate(speaker):
    speaker_id=s
    # print(speaker_id)
    path_to_speaker=os.path.join(path,speaker_id)
    speaker_wav_files=os.listdir(path_to_speaker)
    for b,wav_files in enumerate(speaker_wav_files):
      wav_path=os.path.join(path_to_speaker,wav_files)
      sr, audio = read(wav_path)
      features = get_MFCC(audio, sr)
      # print(speaker_id)
      features=np.append(features,speaker_id)
      features=np.reshape(features,(1,features.shape[0]))
      if a==0 and b==0:
        # first iteration
        output= features
        continue
      output=np.append(output,features,axis=0)
  return output

df_train=dataset_generator(train_path)
df_test=dataset_generator(test_path)
df_valid=dataset_generator(validation_path)

df_train=pd.DataFrame(df_train)
df_test=pd.DataFrame(df_test)
df_valid=pd.DataFrame(df_valid)

df_valid.head()

df_train.head()

df_test.head()

"""## Preprocessing

Normalization function
"""

def normalize(array):
  means=np.mean(array, axis=0)
  std=np.std(array, axis=0)
  array=(array-means)/std
  return array

"""Saving the labels columns separately for each df"""

Y_train=df_train[13]
Y_valid=df_valid[13]
Y_test=df_test[13]

"""Removing labels column from each df"""

df_train=df_train.drop([13], axis=1)
df_valid=df_valid.drop([13], axis=1)
df_test=df_test.drop([13], axis=1)

"""Now checking if labels column removed"""

df_train.head()

df_valid.head()

df_test.head()

"""Convert all columns to numeric first"""

df_train = df_train.apply(pd.to_numeric)
df_valid = df_valid.apply(pd.to_numeric)
df_test = df_test.apply(pd.to_numeric)

df_train

"""Normalising each dataframe"""

normalised_train=normalize(df_train)
normalised_train

normalised_valid=normalize(df_valid)

normalised_test=normalize(df_test)

"""Adding a column of 1 to each dataframe"""

normalised_train.insert(0, 'Bias', 1)

normalised_valid.insert(0, 'Bias', 1)

normalised_test.insert(0, 'Bias', 1)

"""Checking for column of 1"""

normalised_train.head()

normalised_valid.head()

normalised_test.head()

"""Adding Labels column back to each dataframe"""

normalised_train['Labels']=Y_train

normalised_valid['Labels']=Y_valid

normalised_test['Labels']=Y_test

"""Checking if Labels column has been added to each dataframe successfully"""

normalised_train

normalised_valid

normalised_test

"""Saving dataframes as CSV files to Drive"""

normalised_train.to_csv(r'/content/drive/MyDrive/Ml assignmentsa/ml project/Preprocessed Datasets/Train_Preprocessed.csv')

normalised_valid.to_csv(r'/content/drive/MyDrive/Ml assignmentsa/ml project/Preprocessed Datasets/Valid_Preprocessed.csv')

normalised_test.to_csv(r'/content/drive/MyDrive/Ml assignmentsa/ml project/Preprocessed Datasets/Test_Preprocessed.csv')

"""## Sklearn Models"""

normalised_train=pd.read_csv('/content/drive/MyDrive/ml project/Preprocessed Datasets/Train_Preprocessed.csv')
normalised_valid=pd.read_csv('/content/drive/MyDrive/ml project/Preprocessed Datasets/Valid_Preprocessed.csv')
normalised_test=pd.read_csv('/content/drive/MyDrive/ml project/Preprocessed Datasets/Test_Preprocessed.csv')

normalised_train=normalised_train.drop('Unnamed: 0',axis=1)
normalised_test=normalised_test.drop('Unnamed: 0',axis=1)
normalised_valid=normalised_valid.drop('Unnamed: 0',axis=1)

df_train=pd.concat([normalised_train, normalised_valid], ignore_index=True)

df_train.shape

df_test=normalised_test

X_train=df_train.iloc[:,-1:]
Y_train=df_train.iloc[:,-1]
X_test=df_test.iloc[:,-1:]
Y_test=df_test.iloc[:,-1]

Y_train

from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score
from sklearn.neural_network import MLPClassifier
from sklearn.svm import LinearSVC
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import make_classification
from sklearn import svm
from sklearn.metrics import classification_report
from sklearn.metrics import f1_score

"""One hot encoding"""

encoded_labels_test = pd.get_dummies(df_test['Labels'])
encoded_labels_train = pd.get_dummies(df_train['Labels'])

# X_train=normalised_train.to_numpy()[:,0:14]
# Y_train=normalised_train.to_numpy()[:,-1]
# X_test=normalised_test.to_numpy()[:,0:14]
# Y_test=normalised_test.to_numpy()[:,-1]
# X_valid=normalised_valid.to_numpy()[:,0:14]
# Y_valid=normalised_valid.to_numpy()[:,-1]

clf = GaussianNB()
clf.fit(encoded_labels_train, Y_train)
GaussianNB()
preds=clf.predict(encoded_labels_test)
print('accuracy: ', accuracy_score(Y_test, preds))
print('confusion matrix: ', confusion_matrix(Y_test, preds))
print(classification_report(Y_test, preds))

clf = svm.SVC(kernel='linear')
clf.fit(encoded_labels_train, Y_train)

#Predict the response for test dataset
y_pred = clf.predict(encoded_labels_test)
print("Accuracy:",accuracy_score(Y_test, y_pred))
print('f1: ', f1_score(Y_test, y_pred, average='macro'))
print('confusion matrix: ', confusion_matrix(Y_test, y_pred))
#print(classification_report(Y_test, y_pred))

clf = MLPClassifier(hidden_layer_sizes=(128, 64), activation='logistic', solver='sgd', learning_rate_init=0.4 max_iter=5000, random_state=1).fit(encoded_labels_train, Y_train)

"""# Multinomial Logistic Regression

Softmax Function
"""

def softmax(x):
    x=np.array(x, dtype=float)
    # print(x)
    return np.exp(x+0.001) / np.sum(np.exp(x+0.001), axis=0)

"""Cost Function"""

def cross_entropy_loss(X,Y,theta):
  m=X_train.shape[0]
  output = np.dot(X,theta)
  predictions=np.apply_along_axis(softmax,1,output)
  predictions=np.log(predictions+0.001) 
  output=(np.multiply(predictions,Y))*-1
  output=output.sum(axis=1)
  return np.sum(output)/(m)

"""Gradient Descent Function"""

def gradient_descent(X,X_valid,theta,Y,Y_valid,alpha,iterations):
  # X holds training data and is in the shape (m,f)
  # where m is training examples and f is features
  # theta are weight matrixes in the shape (f,c)
  # where f are features and c is number of classes
  # Y is our onehot encoded label matrix in the shape(m,c) where m is exmaples
  # c is classes
  m=X_train.shape[0]
  training_cost=[]
  validation_cost=[]
  for epoch in range(iterations):
    # calculate output
    output = np.dot(X,theta)
    # output is (m,c)
    #put them through softmax to get predictions
    predictions=np.apply_along_axis(softmax,1,output) 
    # now we will calculate error
    error=np.array(predictions-Y)
    # create an array for the derivatives
    # djs will have shape (c,f)
    djs=[]
    for i in range(X.shape[1]):
      # we will multiply every column of the error with the column of x
      a = error * X[:,i][:, None]
      b=(a.sum(axis=0))/m
      # b is going to be an array of c elements
      # we are going to append b to the djs array so get an array of (14,c)
      djs.append(b)
    # update
    djs=np.array(djs)
    theta=theta-(alpha*djs)
    # calculate training costs
    # calculate validation costs
    # append and return that
    training_cost.append(cross_entropy_loss(X,Y,theta))
    validation_cost.append(cross_entropy_loss(X_valid,Y_valid,theta))
  return theta,training_cost, validation_cost

"""Prediction Function"""

def predict(X,thetas,labels):
  output = np.dot(X,theta)
  predictions=np.apply_along_axis(softmax,1,output)
  answers=np.apply_along_axis(np.argmax,1,predictions)
  results=[labels[l] for l in answers]
  return results

"""Running Gradient Descent for a range of iteration values, keeping alpha constant"""

theta= np.random.rand(14,142)
alpha=0.1
iter=[500, 1000, 1500, 2000]

for i in iter:
  theta,training_cost,validation_cost=gradient_descent(X_train,X_valid,theta,encoded_labels_train,encoded_labels_valid,alpha,i)
  plt.plot(training_cost,label="Training")
  plt.plot(validation_cost,label="Validation")
  plt.legend()
  plt.xlabel('Epochs')
  plt.ylabel('Costs')
  plt.title("Costs for iterations " + str(i))
  plt.show()

"""The graphs above show that the optimal number of iterations for convergence is 1000

Now, using 1000 iterations, running for different alpha values
"""

theta= np.random.rand(14,142)

alpha=[0.001,0.01,0.1,1,10,20]
iterations=1000
theta= np.random.rand(14,142)
for a in alpha:
  theta,training_cost,validation_cost=gradient_descent(X_train,X_valid,theta,encoded_labels_train,encoded_labels_valid,a,iterations)
  preds_1=predict(X_test,theta,labels)
  f=f1_score(Y_test, preds_1, average='macro')
  pr=precision_score(Y_test, preds_1, average='macro')
  rc=recall_score(Y_test, preds_1, average='macro')
  acc=accuracy_score(Y_test, preds_1)
  print("For aplha value: ",a)
  print("accuracy: ",acc, "f1 score: ",f)
  print("recall: ",rc, "precision: ",pr)
  print("confusion matrix: ", confusion_matrix(Y_test, preds_1))
  plt.plot(training_cost,label="Training")
  plt.plot(validation_cost,label="Validation")
  plt.legend()
  plt.xlabel('Epochs')
  plt.ylabel('Costs')
  plt.title("Costs with aplha " + str(a))
  plt.show()

"""The above results show that the optimal value of alpha is 20, as it gives the highest accuracy and f1 score of 97%"""

